\section{Audio and Heartbeat}
The audio and heartbeat system run concurrently with the rest of the program. On an operating system supporting neither processes nor threads that means using interrupts to stop normal execution and perform tasks on the side.\\
\par
The idea is to configure the hardware to trigger a hardware interrupt at a regular interval. This interrupt is caught by a system called PIC which transforms it into a software interrupt. The software interrupt ID is used as an offset in a vector to look up a function belonging to the engine. At this point, the CPU is stopped (a.k.a: interrupted) from doing whatever it was doing (likely running the 3D renderer), and it started running the interrupt handler which is called an ISR\footnote{Interrupt Service Routine}. We now have two systems running in parallel.

\includegraphics[width=.9\textwidth]{imgs/drawings/irqs/explanation.png}
\par
 Since interrupts keep triggering constantly from various sources, an ISR must make a choice with what should happen if an IRQ is raised while it is still running. There are two ways to go: Decide it needs a "long" time to run and disable other IRQs via the IMR \footnote{Interrupt Mask Register.}. This way to go introduces the problem of discarding important information such as keyboard input or mouse inputs. Or the ISR can decide not to mask other IRQs and do what it is supposed to do as fast as possible, keeping in mind the routine can be stopped (and never resumed).\\
 \par
 Wolfenstein 3D uses the latter approach and keep things in its ISR very small and short. To this effect everything in the audio and heartbeat system is written in assembly and it avoid "heavy" processing.

\subsection{IRQs and ISRs}
The IRQ and ISR system relies on two chips: The Intel 8254 which is a PIT \footnote{Programmable Interval Timers} and the Intel 8259 which is a PIC \footnote{Programmable Interrupt Counter}. The PIT features a crystal oscillating in square waves. On each edges, it decrements its three counters. When a counter hits zero it generate an IRQ. One counter is connected to the buzzer and generate sounds, one counter is connected to the RAM to automatically perform something called "Memory refresh".  The third counters is connected to the PIC. 
\par
\begin{figure}[H]
\centering
 \includegraphics[width=.5\textwidth]{imgs/drawings/heatbeats.pdf}
 \end{figure}
\par

The PIC's hardware IRQ-0 to IRQ-8 are mapped to the Interrupt Vector starting at Offset 8 (resulting in mapping to software interrupts INT08 to INT0F).\\

\par
\begin{figure}[H]
\centering
\begin{tabularx}{\textwidth}{ X X  }
  \toprule
  \textbf{IRQ} & \textbf{Type} \\ \bottomrule
0 & System timer \\
1 & Keyboard controller \\
3 & Serial port COM2 \\ 
4 & Serial port COM1 \\
5 & Line print terminal 2 \\
6 & Floppy controller \\
7 & Line print terminal 1 \\
8 & RTC timer \\
12 & Mouse controller \\
13 & Math co-processor \\
14 & ATA channel 1 \\
15 & ATA channel 2  \\
\bottomrule
\end{tabularx}
\caption{IRQs and routines. Notice \#8 which is associated with the RTC Timer. It usually updates the operating system clock.}
\end{figure}
Using these two chips and placing its own function at Interrupt Vector Table \#8, the engine can stop its runtime at a regular time interval, effectively implementing a subsystem running concurrently with everything else.\\
\par
The engine can decide at what frequency to be interrupted, depending on that type of sound/music it needs to play (digitized sounds are much more taxing than musics). As a result, three different ISRs can be found at IVT \#8: 
\begin{enumerate}
\item \cw{SDL\_t0ExtremeAsmService} when running at 7000Hz, to play digitized (PCM) sound.
\item \cw{SDL\_t0FastAsmService} when running at 700Hz when playing music and FM sound effects.
\item \cw{SDL\_t0SlowAsmService} when running at 140Hz to play sound effects on the beeper via PWM.
\end{enumerate}
\par



\subsection{PIT and PIC}
The PIT chips runs at 1.193182 MHz. That sounds like an odd choice from the hardware designers. The reason of this choice has an uncanny origin. Back in the 1980 when the first IBM PC 5150 was designed, the common oscillator used in television circuitry was running at 14.31818 MHz. Because it was mass produced, it was also very cheap. The decision to use TV oscillator helped to drive the cost of the machine down. Engineers built the PC timer around it, dividing the frequency by 3 for the CPU (that is why the Intel ran at 4.7Mhz), dividing by 4 to 3.57Mhz for the CGA video card. By logically ANDing these signals together a frequency equivalent to the base frequency divided by 12 was created. This frequency is 1.1931816666 MHz. By 1991 the oscillator were much cheaper and could have used any frequency but backward compatibility forbidden it.\\
\par














\subsection{Hearbeats}
Each time the interrupt system triggers, before taking care of the audio requests, it run an other small (yet paramound) system. The sole goal of the heartbeat system is to maintain a 64 bits variable: \cw{TimeCount}.\\
\par
\begin{minipage}{\textwidth}
\lstinputlisting[language=C,morekeywords={longword}]{code/timecount.c}
\end{minipage}
\par
It is updated at a rate of 70 units per seconds (to match VGA update rate of 70Hz). These units are called "ticks". Depending on how fast the audio system runs (from 150Hz to 7000Hz) it adjust how much it should increase \cw{TimeCount}.\\
\par
Every system in the engine uses this variable to pace itself. The renderer will not start rendering a frame until at least one tick has passed. The A.I system express action duration in tick units. The input sampler checks for how long a key was pressed, the list goes on. Everything interacting with humans uses \cw{TimeCount}.\\













\subsection{Audio system}
The audio system is complex because of the fragmentation of the audio devices it can deal with. The early 90s was a time before Windows 95 harnessed all audio cards under DirectSound common API. Each development studio had to write their own abstraction layer and id Software was not exception. At high level, the Sound Manager offers a lean API divided in two categories, one for sounds and an other for music.\\
\par
\begin{minipage}{\textwidth}
\lstinputlisting[language=C,morekeywords={longword}]{code/sound.h}
\end{minipage}
\par
But in the implementation lays a maze of functions directly accessing the I/O port of four sound outputs: Adlib, SoundBlaster, Buzzer and Disney Sound source. All belong to one of the three supported family of sound generator: FM Synthesizer (Frequency Modulation), PCM (Pulse Code Modulation) or PWM (Pulse Width Modulation).\\


\subsection{Music}
Playing music is not too messy since only PC equipped with a Yamaha YM3812 FM synthesizer can play tracks (a.k.a: With an Adlib or a SoundBlaster inside). Because SoundBlaster made its programming interface compatible with Adlib there is only one code path to both cards. There is not a lot of magic here since this part uses a piece of hardware well designed and dedicated to this specific task. There are however a few cool tricks.\\
\par
The music system streams data to the sound cards.  Musics in the 90s were not in digitalized format like CD or MP3 nowadays (that would have taken too much storage space and bandwidth). Instead musics are stored as series of notes played on channels together simulating instruments. The format used is close to the notorious MIDI but with a few variation and is called IMF\footnote{Id Music Format}. It is proprietary to id software and designed with OPL2 in mind (the raw format is exactly what is sent to the Adlib/Soundblaster synthesizer with no transformations). IMF has a hardcoded playback rate and music notes are played at 700 Hz.\\
\par
Hardware limitations dictated certain aspects of the design of the musics. The FM synthesizer (OPL2) has 9 channels (a.k.a instruments). Yet the composer, Bobby Prince, was asked to use only channel 1 to 8 for the musics. This little trick allows to multiplex music and sound effects on an AdLib cards since it leave channel 0 available at all time (the SoundBlaster plays sound differently).\\




\subsubsection{OPL2/YM3812 Programming}
\par
Programming the OPL2 output is esoteric to say the least. Adlib and Creative did publish SDK but they were expensive.  Documentation was sparse and often cryptic. Today it is almost impossible to find.\\
\par
The OPL2 is made of 9 channels able to emulate an instrument. Each channel is made of two oscillator, a Modulator which outputs are fed into a Carrier's input. Each channel has individual settings including Frequency, Envelope (Attack rate, Decay rate, Sustain level, Release rate, Vibrato). Each oscillator can also pick a waveform (these uncanny form are what gave the YM3812 is recognizable sound).\\
\par
 To control all these channels, a developers must configure the OPL2's 244 internal registers. They are all accessed via two external ports mapped in the PC RAM. One is to set the card's internal register and the other one to read/write data to it.\\
\par
\begin{minipage}{\textwidth}
\lstinputlisting[language=C,morekeywords={longword}]{code/audio_ports.c}
\end{minipage}
\par
When the AdLib first got released in 1986, developers were instructed to send data "as fast as possible". At 4.77Mhz, a PC was not able to out-pace the Adlib. But as CPU got faster issues started to arise and the card was not able to keep up and the Programming Guide was amended.\\
\par

\begin{fancyquotes}
After writing to the register port, you must wait twelve cycles before sending the data; after writing the data, eighty-four cycles must elapse before any other sound card operation may be performed\footnote{http://www.oldskool.org/guides/oldonnew/sound}.
 \bigskip \\
 Alternatively you can issue one IN instruction.
 \bigskip \\
 \end{fancyquotes}
\\
\par
Later, reliable specs were published.\\
\par
\begin{fancyquotes}
Wait three point three (3.3) microseconds for the address, and twenty-three (23) microseconds for the data.\\
 \end{fancyquotes}
 

\par
The engine does not know about any of the details of the OPL2. There is zero abstraction layer or transformation here. An IMF song is made of a serie of messages containing exactly the values to write to the register and data ports of the OPL2. Each message is four bytes:\\
\par
\begin{minipage}{\textwidth}
\lstinputlisting[language=C,morekeywords={longword}]{code/adlib_message.c}
\end{minipage}
\par
The \cw{reg} byte is sent to port \cw{0x388}, the \cw{data} byte is sent to \cw{0x389} and the \cw{delay} 2 bytes is used to tell how much time to wait before sending the next register/data to the card. The stream is hard-coded at 700Hz and the delay is expressed in this unit: A value of 700 means to wait 1000ms before sending an other command. Whenever there is a music playing the engine runs at no less than 700Hz (it can run at 7000Hz if it is also playing digitized sound but that results in noops for music playback.). A value of zero means the next message should be sent immediately.\\
\par
Overall the music part is simple to execude because almost everything has been pre-processed via IMF. Everytime the audio system wakes up, it checks if music packet should be sent, sent them and move to the sound effects.










\section{Sound effects}
Sound effects are were things become complicated. None of the card use the same format and
the audio configurations are many. The sound settings screen illustrate well how complex it is.
\par
\begin{figure}[H]
\centering
 \fullimage{audio/audio_settings.png}
 \end{figure}
\par
Sound effects and Digitized sounds are actually the same thing. Sound effects are stored in three formats. Once for PC Speaker, once for Adlib and once for SoundBlaster/Disney Sound Source. The sounds are stored in the \cw{AudioT} archive by Muse. Sounds are segregated by format but always stored in the same order. This way a sound can be accessed in three formats by using \cw{STARTPCSOUNDS} + \cw{sound\_ID} or \cw{STARTADLIBSOUNDS} + \cw{sound\_ID}\\

\par
\begin{minipage}{\textwidth}
\lstinputlisting[language=C,morekeywords={longword}]{code/muse_header.c}
\end{minipage}
\par
Strangely, only PC speaker and Adlib sounds are stored in the \cw{AUDIOT.*} files, the digitized sound are in the \cw{VMSWAP.*} archive. As a result, offset \cw{STARTDIGISOUNDS} is never used.\\
\note{Question for the developers: Why not include the sb sounds in AudioT?} 
\par



\subsection{Sound effects: Adlib}
Adlib only has a FM synthesize and it is used to play sound on its Channel 1. This is done the same way music as previously described (via IMF) so it is not discussed further here.












\subsection{Disney Sound sound system: PCM}
The Disney Source is simple to program\footnote{The Programmer's Guide to the Disney Sound Source is a wooping 2 pages!} because it can do only one thing. It plays PCM audio in format 8 bits at 7000Hz on a single channel. And that's it, nothing more, nothing less. As soon as it is plugged in the parallel port, its 8 bits DAC will read from an internal 16 bytes deep FIFO and turn them into sound via its integrated loud speaker.\\ 
\par
Hence every times the audio system awakes, it read the DAC status to check if the FIFO is not full. If it is not, the engine pushes as many bits as possible until the FIFO is full and returns. When the FIFO gets empty, the Disney Sound source stops making noise.\\
\par










\par
\subsection{SoundBlaster system: PCM}
Since the SoundBlaster also supports 7000Hz PCM, it uses the same sound effects files as the Disney Source. However it features a DSP which is DMA capable. As a result, the CPU does not have to waste cycle transferring data. The audio system only have to make sure it is running at 7000Hz and point the DMA to the right memory address every times it crosses the end of a 16K segment via a DMA routine callback.
\par








\par
\subsection{SoundBlaster Pro system}
\par

On a "high-end" stereo SoundBlaster Pro with left and right channel, the sound is more elaborated: The sound source is rotated with the same formula as the raycaster. Using SOH-CAH-TOA.\\
\par
\begin{figure}[H]
\centering
 \includegraphics[width=\textwidth]{imgs/drawings/audio_y_rotate.png}
 \end{figure}
 \par
 \begin{figure}[H]
\centering
 \includegraphics[width=\textwidth]{imgs/drawings/audio_x_rotate.png}
 \end{figure}
\par
Based on the distance, an intensity (hardcoded 0-15) is send to the left and right speaker.\\
\par
\bu{Trivia :} Plugging a sound blaster card was not enough to hear sound. This was before "plug \& play" was introduced by Windows 95. The user had to write a special line in the startup command of the PC (\cw{autoexec.bat}).\\
\par 
\begin{minipage}{\textwidth}
\lstinputlisting[language=C]{code/soundblasterconf.c}
\end{minipage}
\par
This line defines a variable \cw{BLASTER} which the engine retrieves and parses at runtime with \cw{getenv}. \cw{A} tells what port the card is using. \cw{I} gives away the interrupt vector it is associated with. Finally \cw{D} gives the DMA channel to use for data transfer. Of course for all this to work the sound card had to be configured accordingly via its jumpers connectors.
See \cw{SDL\_SBPlaySeg} and the ISR \cw{SDL\_SBService} 




 
\subsection{Sound on PC Speaker: PWM}
The hardware chapter described a problem for sound effects. The default PC speaker can only generate square waves resulting in long beep which are not acceptable for game.\\

\par
 \begin{fancyquotes}
  The PC speaker is normally meant to reproduce a square wave via only 2 levels of output (the speaker is driven by only two voltage levels, typically 0 V and 5 V). However, by carefully timing a short pulse (i.e. going from one output level to the other and then back to the first), and by relying on the speaker's physical filtering properties (limited frequency response, self-inductance, etc.), the end result corresponds to intermediate sound levels. This effectively allows the speaker to function as a crude 6 bit DAC, thereby enabling approximate playback of PCM audio.\\
  \par
  This technique is called pulse-width modulation (PWM).
 \end{fancyquotes}
\par
  
The idea is to approximate a signal using square waves. It is simpler to understand when the signal is a simple sinusoide:
\par
\begin{figure}[H]
\centering
 \includegraphics[width=\textwidth]{imgs/drawings/pwm/sinuois.png}
 \caption{The original sound.}
 \end{figure}
\par

\par
\begin{figure}[H]
\centering
 \includegraphics[width=\textwidth]{imgs/drawings/pwm/pwm_approximation.png}
 \caption{The same sound approximated with PWM.}
 \end{figure}
\par

To do this, the audio system once again relies on the PIT chipset. Counter 0 is used to trigger the audio system. Counter 1 cannot be used either since it is used to refresh the RAM periodically. Counter 2 however is directly connected to the PC Speaker. The trick is to set this Counter 2 to square wave mode (Mode 3) so it will repeats after it triggers and program the desired square wave frequency. \\
\par
\begin{figure}[H]
\centering
\begin{tabularx}{\textwidth}{ X X  }
  \toprule
  \textbf{Mode} & \textbf{Type} \\ \bottomrule
1 & Hardware Re-triggerable One-shot\\
2 & Rate Generator\\
3 & Square Wave Generator\\
4 & Software Triggered Strobe\\
5 & Hardware Triggered Strobe\\
\bottomrule
\end{tabularx}
\caption{Available mode of a PIT counter.}
\end{figure}
\par 
When instructed to play a PWM sound effect, the audio system set itself to run at 140Hz via PIC Counter 0. Every times it wakes up, it reads the frequency to maintain for the next 1/140th of a seconds and write it to Counter 2. The frequencies to use are encoded as a stream of byte, the value is decoded as follow:\\
\par 
\begin{minipage}{\textwidth}
\lstinputlisting[language=C]{code/pwm.c}
\end{minipage}
\par
In the assembly, three I/O port are accessed:\\
\par
\begin{minipage}{\textwidth}
\lstinputlisting[language=C]{code/pwm_code_header.c}
\end{minipage}
\par
Notice how the $ * 60$ is not calculated. Once again the engine tries to save as much CPU time as possible by using a bit of RAM. The frequency is read from a loopup table \cw{pcSoundLookup}:\\
\par
\begin{minipage}{\textwidth}
\lstinputlisting[language=C]{code/pcSoundLookup.c}
\end{minipage}
\par
Notice how \cw{6b} (\cw{10110110}) is sent to the PIC Command register (\cw{pcTAccess}=\cw{0x43}):
\begin{itemize}
	\item \cw{10} = Target Counter 2.
 	\item \cw{11} = High \& low byte of counter updated.
	\item \cw{011} = Square Wave Generator.
	\item \cw{0} = 16 bits mode.
\end{itemize}
\par
\begin{minipage}{\textwidth}
\lstinputlisting[language={[x86masm]Assembler}]{code/pwm_code.asm}
\end{minipage}
\par
The end result was not great, but it was better than a beep\footnote{Lucas Art however obtained surprisingly good results for they game Monkey Island. See the video "LGR - Evolution of PC Audio - As Told by Secret of Monkey Island", https://www.youtube.com/watch?v=a324ykKV-7Y.}.\\
\par

\bu{Hidden feature :} The source code features an audio code path that was never allowed to ship. It can play digitized sound via the PC Speaker.\\

\par 
\begin{minipage}{\textwidth}
\lstinputlisting[language=C]{code/sound_fork.c}
\end{minipage}
\par
Notice the \cw{SDL\_PCPlaySample} path allowing PCM to be played on the buzzer. This codepath was never enabled in shipping product.
\footnote{You can hear the difference on youtube: "Wolfenstein 3D Hack - Digitized PC Speaker Sound Effects" at https://www.youtube.com/watch?v=1BtlsjJRnFU}.\\
\par
\note{Why was this never shipped?}














